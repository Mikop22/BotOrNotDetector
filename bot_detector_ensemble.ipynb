{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Meta-Learner: Stacked Generalization\n",
    "\n",
    "Logistic regression over OOF probabilities from three complementary base learners:\n",
    "\n",
    "| Model | Signal | Source |\n",
    "|-------|--------|--------|\n",
    "| **XGBoost** | Metadata & temporal | 35 features |\n",
    "| **XLM-R** | Linguistic | Post-text [CLS] embeddings |\n",
    "| **BotRGCN** | Relational | GNN on behavioural kNN graph |\n",
    "\n",
    "**OOF protocol.** Every user's base-learner probability comes from a model that never saw that user during training (5-fold stratified CV for all three). The meta-learner trains on all 889 users; nested CV yields an unbiased performance estimate.\n",
    "\n",
    "**Prerequisites:** run `bot_detector.ipynb`, `bot_detector_xlmr.ipynb`, and `bot_detector_rgcn.ipynb` first.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Setup ===\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "DATASET_IDS = (30, 31, 32, 33)\n",
    "RANDOM_STATE = 42\n",
    "K = 5  # number of CV folds\n",
    "KNN_K = 15  # kNN neighbours per relation in GNN graph\n",
    "GNN_HIDDEN = 128  # GNN hidden dimension\n",
    "GNN_EPOCHS = 200  # GNN training epochs\n",
    "ARTIFACTS_BASE_DIR = Path(\"artifacts\") / \"ensemble\"\n",
    "\n",
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    \"\"\"Best-effort deterministic seeding across numpy/python/torch.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def ensure_run_dir(seed: int, calibration_mode: str = \"raw\") -> Path:\n",
    "    \"\"\"Create a timestamped artifact directory for this run.\"\"\"\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = ARTIFACTS_BASE_DIR / f\"run_{ts}_seed{seed}_{calibration_mode}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def resolve_best_xlmr_checkpoint(fold: int, phase_dir_root: Path = Path(\"xlmr_cv\")) -> Path:\n",
    "    \"\"\"Resolve best checkpoint for a fold with robust fallback behavior.\"\"\"\n",
    "    fold_dir = phase_dir_root / f\"fold{fold}_phase3\"\n",
    "    if not fold_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing XLM-R fold directory: {fold_dir}\")\n",
    "\n",
    "    trainer_states = sorted(fold_dir.glob(\"checkpoint-*/trainer_state.json\"))\n",
    "    if trainer_states:\n",
    "        # Prefer latest trainer_state.json, then use its best_model_checkpoint.\n",
    "        state_path = trainer_states[-1]\n",
    "        with open(state_path) as f:\n",
    "            trainer_state = json.load(f)\n",
    "        best_ckpt = trainer_state.get(\"best_model_checkpoint\")\n",
    "        if best_ckpt:\n",
    "            best_path = Path(best_ckpt)\n",
    "            if best_path.exists():\n",
    "                return best_path\n",
    "\n",
    "    ckpt_dirs = sorted(\n",
    "        [p for p in fold_dir.glob(\"checkpoint-*\") if p.is_dir()],\n",
    "        key=lambda p: int(p.name.split(\"-\")[-1]),\n",
    "    )\n",
    "    if not ckpt_dirs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No valid checkpoint directories found for fold {fold} in {fold_dir}\"\n",
    "        )\n",
    "    return ckpt_dirs[-1]\n",
    "\n",
    "\n",
    "def load_bot_ids(dataset_id: int) -> set:\n",
    "    path = DATA_DIR / f\"dataset.bots.{dataset_id}.txt\"\n",
    "    if not path.exists():\n",
    "        return set()\n",
    "    with open(path) as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "\n",
    "def load_posts_and_users(dataset_id: int) -> dict:\n",
    "    path = DATA_DIR / f\"dataset.posts&users.{dataset_id}.json\"\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "set_global_seed(RANDOM_STATE)\n",
    "print(\"Setup complete.\")"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost Out-of-Fold Predictions\n",
    "\n",
    "Reproduce the exact feature engineering from `bot_detector.ipynb`, then run 5-Fold\n",
    "Stratified CV collecting **validation probabilities** from each fold.\n",
    "\n",
    "*Feature pipeline must match the source notebook exactly; otherwise the OOF estimates are not comparable across runs.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# XGBoost 5-Fold OOF Predictions\n",
    "from collections import defaultdict\n",
    "from scipy.stats import entropy as scipy_entropy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def extract_user_features(posts, users, bot_ids):\n",
    "    by_author = defaultdict(list)\n",
    "    for p in posts:\n",
    "        by_author[p[\"author_id\"]].append(p)\n",
    "    rows = []\n",
    "    for author_id, author_posts in by_author.items():\n",
    "        texts = [p[\"text\"] for p in author_posts]\n",
    "        created = [pd.to_datetime(p[\"created_at\"]) for p in author_posts]\n",
    "        row = {\"author_id\": author_id, \"post_count\": len(author_posts),\n",
    "               \"avg_text_length\": np.mean([len(t) for t in texts]),\n",
    "               \"unique_langs\": len(set(p.get(\"lang\", \"\") for p in author_posts)),\n",
    "               \"has_url_ratio\": np.mean([1 if \"http\" in t else 0 for t in texts]),\n",
    "               \"is_bot\": 1 if author_id in bot_ids else 0}\n",
    "        if len(created) > 1:\n",
    "            created.sort()\n",
    "            gaps = np.diff(created).astype(\"timedelta64[s]\").astype(float)\n",
    "            row[\"avg_post_gap_seconds\"] = np.mean(gaps)\n",
    "            row[\"min_post_gap_seconds\"] = np.min(gaps)\n",
    "        else:\n",
    "            row[\"avg_post_gap_seconds\"] = np.nan\n",
    "            row[\"min_post_gap_seconds\"] = np.nan\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def levenshtein_distance(a, b):\n",
    "    if len(a) < len(b):\n",
    "        a, b = b, a\n",
    "    prev = list(range(len(b) + 1))\n",
    "    for i, ca in enumerate(a):\n",
    "        curr = [i + 1]\n",
    "        for j, cb in enumerate(b):\n",
    "            substitution_cost = 0 if ca == cb else 1\n",
    "            curr.append(\n",
    "                min(\n",
    "                    prev[j] + substitution_cost,\n",
    "                    prev[j + 1] + 1,\n",
    "                    curr[j] + 1,\n",
    "                )\n",
    "            )\n",
    "        prev = curr\n",
    "    return prev[-1]\n",
    "\n",
    "\n",
    "def digit_density(s):\n",
    "    return sum(ch.isdigit() for ch in s) / len(s) if s else 0.0\n",
    "\n",
    "\n",
    "def iat_entropy(timestamps, n_bins=20):\n",
    "    if len(timestamps) < 3:\n",
    "        return np.nan\n",
    "    gaps = np.diff(sorted(timestamps)).astype(\"timedelta64[s]\").astype(float)\n",
    "    counts, _ = np.histogram(gaps, bins=n_bins)\n",
    "    return float(scipy_entropy(counts, base=2))\n",
    "\n",
    "\n",
    "def burstiness(timestamps):\n",
    "    if len(timestamps) < 3:\n",
    "        return np.nan\n",
    "    gaps = np.diff(sorted(timestamps)).astype(\"timedelta64[s]\").astype(float)\n",
    "    mu, sigma = np.mean(gaps), np.std(gaps, ddof=1)\n",
    "    return (sigma - mu) / (sigma + mu) if (sigma + mu) != 0 else 0.0\n",
    "\n",
    "\n",
    "def activity_vector(timestamps):\n",
    "    vec = [0] * 24\n",
    "    for ts in timestamps:\n",
    "        vec[ts.hour] += 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "def lang_mismatch_ratio(author_posts, expected_lang):\n",
    "    if not author_posts:\n",
    "        return 0.0\n",
    "    mismatch_count = sum(\n",
    "        1 for p in author_posts if p.get(\"lang\", expected_lang) != expected_lang\n",
    "    )\n",
    "    return mismatch_count / len(author_posts)\n",
    "\n",
    "\n",
    "def screen_name_entropy(screen_name, normalize=True):\n",
    "    if not screen_name:\n",
    "        return 0.0\n",
    "    s = screen_name.strip().lower()\n",
    "    if not s:\n",
    "        return 0.0\n",
    "\n",
    "    counts = {}\n",
    "    for ch in s:\n",
    "        counts[ch] = counts.get(ch, 0) + 1\n",
    "\n",
    "    n = len(s)\n",
    "    ent = -sum((c / n) * np.log2(c / n) for c in counts.values())\n",
    "    if normalize and len(counts) > 1:\n",
    "        ent /= np.log2(len(counts))\n",
    "    return ent\n",
    "\n",
    "def build_feature_df(dataset_id):\n",
    "    bot_ids = load_bot_ids(dataset_id)\n",
    "    data = load_posts_and_users(dataset_id)\n",
    "    posts, users = data[\"posts\"], data[\"users\"]\n",
    "    dataset_lang = data.get(\"lang\", \"en\")\n",
    "\n",
    "    df = extract_user_features(posts, users, bot_ids)\n",
    "\n",
    "    name_distance_map = {\n",
    "        u[\"id\"]: levenshtein_distance(\n",
    "            (u.get(\"username\", \"\") or \"\").lower(),\n",
    "            (u.get(\"name\", \"\") or \"\").lower(),\n",
    "        )\n",
    "        for u in users\n",
    "    }\n",
    "    digit_density_map = {\n",
    "        u[\"id\"]: digit_density(u.get(\"username\", \"\"))\n",
    "        for u in users\n",
    "    }\n",
    "\n",
    "    df[\"levenshtein_name_dist\"] = df[\"author_id\"].map(name_distance_map)\n",
    "    df[\"digit_density\"] = df[\"author_id\"].map(digit_density_map)\n",
    "\n",
    "    by_author_timestamps = defaultdict(list)\n",
    "    for p in posts:\n",
    "        by_author_timestamps[p[\"author_id\"]].append(pd.to_datetime(p[\"created_at\"]))\n",
    "\n",
    "    df[\"iat_entropy\"] = df[\"author_id\"].map(\n",
    "        {aid: iat_entropy(ts) for aid, ts in by_author_timestamps.items()}\n",
    "    )\n",
    "    df[\"burstiness\"] = df[\"author_id\"].map(\n",
    "        {aid: burstiness(ts) for aid, ts in by_author_timestamps.items()}\n",
    "    )\n",
    "\n",
    "    activity_df = pd.DataFrame.from_dict(\n",
    "        {aid: activity_vector(ts) for aid, ts in by_author_timestamps.items()},\n",
    "        orient=\"index\",\n",
    "        columns=[f\"hour_{h}\" for h in range(24)],\n",
    "    )\n",
    "    activity_df.index.name = \"author_id\"\n",
    "    activity_df = activity_df.reset_index()\n",
    "    df = df.merge(activity_df, on=\"author_id\", how=\"left\")\n",
    "\n",
    "    by_author_posts = defaultdict(list)\n",
    "    for p in posts:\n",
    "        by_author_posts[p[\"author_id\"]].append(p)\n",
    "\n",
    "    df[\"lang_mismatch_ratio\"] = df[\"author_id\"].map(\n",
    "        {aid: lang_mismatch_ratio(ap, dataset_lang) for aid, ap in by_author_posts.items()}\n",
    "    )\n",
    "    df[\"screen_name_entropy\"] = df[\"author_id\"].map(\n",
    "        {u[\"id\"]: screen_name_entropy(u.get(\"username\", \"\")) for u in users}\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Build combined DataFrame\n",
    "combined_df = pd.concat([build_feature_df(did) for did in DATASET_IDS], ignore_index=True)\n",
    "\n",
    "exclude_cols = {\"author_id\", \"is_bot\", \"min_post_gap_seconds\"}\n",
    "feature_cols = [c for c in combined_df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"Combined: {len(combined_df)} users  ({combined_df['is_bot'].sum()} bots)\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "\n",
    "# XGBoost 5-Fold OOF\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_all = combined_df[feature_cols].fillna(0)\n",
    "y_all = combined_df[\"is_bot\"].values\n",
    "xgb_oof_probs = np.zeros(len(combined_df), dtype=np.float64)\n",
    "xgb_oof_fold = np.full(len(combined_df), -1, dtype=np.int32)\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X_all, y_all), 1):\n",
    "    X_tr, X_val = X_all.iloc[tr_idx], X_all.iloc[val_idx]\n",
    "    y_tr, y_val = y_all[tr_idx], y_all[val_idx]\n",
    "    fold_scale = (y_tr == 0).sum() / max(y_tr.sum(), 1)\n",
    "    fold_model = xgb.XGBClassifier(n_estimators=500, max_depth=4, learning_rate=0.05,\n",
    "                                    scale_pos_weight=fold_scale, colsample_bytree=0.5,\n",
    "                                    eval_metric=\"logloss\", early_stopping_rounds=30,\n",
    "                                    random_state=RANDOM_STATE)\n",
    "    fold_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    xgb_oof_probs[val_idx] = fold_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_oof_fold[val_idx] = fold\n",
    "    f1 = f1_score(y_val, (xgb_oof_probs[val_idx] >= 0.5).astype(int), average=\"binary\")\n",
    "    print(f\"Fold {fold}: F1={f1:.4f}  (val size={len(val_idx)})\")\n",
    "\n",
    "assert np.isfinite(xgb_oof_probs).all(), \"XGBoost OOF contains non-finite values\"\n",
    "assert (xgb_oof_fold > 0).all(), \"Some users are missing XGBoost OOF fold assignments\"\n",
    "\n",
    "xgb_oof_f1 = f1_score(y_all, (xgb_oof_probs >= 0.5).astype(int), average=\"binary\")\n",
    "print(f\"\\nXGBoost OOF F1 (all {len(combined_df)} users): {xgb_oof_f1:.4f}\")"
   ],
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Combined: 889 users  (184 bots)\n",
      "Features: 35\n",
      "Fold 1: F1=0.9041  (val size=178)\n",
      "Fold 2: F1=0.8358  (val size=178)\n",
      "Fold 3: F1=0.8732  (val size=178)\n",
      "Fold 4: F1=0.8219  (val size=178)\n",
      "Fold 5: F1=0.8824  (val size=177)\n",
      "\n",
      "XGBoost OOF F1 (all 889 users): 0.8636\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XLM-R Out-of-Fold Predictions\n",
    "\n",
    "Load the saved fold checkpoints from `xlmr_cv/fold{k}_phase3/` and predict on each\n",
    "fold's validation users. Apply softmax to convert logits \u2192 P(bot).\n",
    "\n",
    "*Each fold uses its own best checkpoint (by val loss); we predict only on that fold\u2019s held-out users. No model ever sees its prediction targets during training.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# XLM-R OOF: Build text DataFrame + Load Fold Checkpoints ===\n",
    "import emoji\n",
    "import gc\n",
    "from transformers import XLMRobertaTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "MAX_LENGTH = 512\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LENGTH, padding=\"max_length\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text.strip()\n",
    "    t = emoji.demojize(t, delimiters=(\":\", \":\"))\n",
    "    t = re.sub(r\"https?://\\S+\", \"<URL>\", t)\n",
    "    t = re.sub(r\"@[A-Za-z0-9_]+\", \"<USER>\", t)\n",
    "    return t\n",
    "\n",
    "def build_user_text_df(dataset_id):\n",
    "    bot_ids = load_bot_ids(dataset_id)\n",
    "    data = load_posts_and_users(dataset_id)\n",
    "    by_author = defaultdict(list)\n",
    "    for p in data[\"posts\"]:\n",
    "        by_author[p[\"author_id\"]].append(preprocess_text(p.get(\"text\", \"\") or \"\"))\n",
    "    rows = []\n",
    "    for aid, texts in by_author.items():\n",
    "        text = \" [SEP] \".join(t for t in texts if t)\n",
    "        rows.append({\"author_id\": aid, \"text\": text if text else \"\", \"is_bot\": 1 if aid in bot_ids else 0})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "text_combined_df = pd.concat([build_user_text_df(did) for did in DATASET_IDS], ignore_index=True)\n",
    "\n",
    "# Keep fold ordering identical to the original XLM-R export to avoid\n",
    "# checkpoint/fold mismatch and label leakage.\n",
    "_xlmr_npz = np.load(\"rgcn_features/xlmr_features.npz\", allow_pickle=True)\n",
    "canonical_xlmr_aids = list(_xlmr_npz[\"author_ids\"])\n",
    "assert set(canonical_xlmr_aids) == set(text_combined_df[\"author_id\"].unique()), \\\n",
    "    \"User set mismatch between XLMR export and ensemble text data\"\n",
    "bot_lookup = text_combined_df.drop_duplicates(\"author_id\").set_index(\"author_id\")[\"is_bot\"]\n",
    "cv_user_ids = pd.DataFrame({\n",
    "    \"author_id\": canonical_xlmr_aids,\n",
    "    \"is_bot\": [int(bot_lookup[a]) for a in canonical_xlmr_aids],\n",
    "})\n",
    "print(f\"XLMR fold alignment: using canonical ordering from xlmr_features.npz ({len(cv_user_ids)} users)\")\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Collect OOF probabilities\n",
    "skf_xlmr = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\n",
    "xlmr_oof_probs = np.full(len(text_combined_df), np.nan, dtype=np.float64)\n",
    "xlmr_oof_fold = np.full(len(text_combined_df), -1, dtype=np.int32)\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf_xlmr.split(cv_user_ids, cv_user_ids[\"is_bot\"]), 1):\n",
    "    fold_val_ids = set(cv_user_ids.iloc[val_idx][\"author_id\"])\n",
    "    fold_val_mask = text_combined_df[\"author_id\"].isin(fold_val_ids)\n",
    "    fold_val_df = text_combined_df[fold_val_mask].reset_index(drop=True)\n",
    "\n",
    "    best_ckpt = resolve_best_xlmr_checkpoint(fold)\n",
    "    print(f\"Fold {fold}: Loading {best_ckpt}\")\n",
    "\n",
    "    fold_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt, num_labels=2)\n",
    "    fold_model = fold_model.to(device)\n",
    "    fold_model.eval()\n",
    "\n",
    "    fold_val_ds = Dataset.from_pandas(fold_val_df[[\"text\"]].reset_index(drop=True))\n",
    "    fold_val_ds = fold_val_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "    fold_val_ds.set_format(\"torch\")\n",
    "\n",
    "    fold_logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in DataLoader(fold_val_ds, batch_size=8, shuffle=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            fold_logits.append(fold_model(**batch).logits.cpu().numpy())\n",
    "\n",
    "    fold_logits = np.concatenate(fold_logits, axis=0)\n",
    "    fold_probs = softmax(fold_logits, axis=1)[:, 1]\n",
    "\n",
    "    val_positions = np.where(fold_val_mask.values)[0]\n",
    "    xlmr_oof_probs[val_positions] = fold_probs\n",
    "    xlmr_oof_fold[val_positions] = fold\n",
    "\n",
    "    f1 = f1_score(fold_val_df[\"is_bot\"].values, (fold_probs >= 0.5).astype(int), average=\"binary\")\n",
    "    print(f\"  Fold {fold} F1={f1:.4f}  (val size={len(fold_val_df)})\")\n",
    "\n",
    "    del fold_model, fold_logits, fold_val_ds\n",
    "    gc.collect()\n",
    "    if device.type == \"mps\": torch.mps.empty_cache()\n",
    "\n",
    "assert not np.isnan(xlmr_oof_probs).any(), \"Some users have no XLM-R OOF prediction!\"\n",
    "assert (xlmr_oof_fold > 0).all(), \"Some users are missing XLM-R OOF fold assignments\"\n",
    "xlmr_oof_f1 = f1_score(text_combined_df[\"is_bot\"].values,\n",
    "                        (xlmr_oof_probs >= 0.5).astype(int), average=\"binary\")\n",
    "print(f\"\\nXLM-R OOF F1 (all {len(text_combined_df)} users): {xlmr_oof_f1:.4f}\")"
   ],
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "XLMR fold alignment: using canonical ordering from xlmr_features.npz (889 users)\n",
      "Device: mps\n",
      "Fold 1: Loading xlmr_cv/fold1_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1706.62it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178/178 [00:00<00:00, 1762.79 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  Fold 1 F1=0.8947  (val size=178)\n",
      "Fold 2: Loading xlmr_cv/fold2_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1746.87it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178/178 [00:00<00:00, 2143.18 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  Fold 2 F1=0.9189  (val size=178)\n",
      "Fold 3: Loading xlmr_cv/fold3_phase3/checkpoint-135\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1736.12it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178/178 [00:00<00:00, 2050.20 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  Fold 3 F1=0.9610  (val size=178)\n",
      "Fold 4: Loading xlmr_cv/fold4_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1741.14it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178/178 [00:00<00:00, 2033.84 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  Fold 4 F1=0.9114  (val size=178)\n",
      "Fold 5: Loading xlmr_cv/fold5_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1749.36it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 177/177 [00:00<00:00, 2122.32 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  Fold 5 F1=0.8485  (val size=177)\n",
      "\n",
      "XLM-R OOF F1 (all 889 users): 0.9086\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BotRGCN Out-of-Fold Predictions (K-Fold Transductive)\n",
    "\n",
    "All 889 nodes stay in the graph (message passing needs the full topology).\n",
    "For each fold we rotate which nodes compute loss **and rebuild the kNN graph**\n",
    "so that val nodes connect only to that fold's train nodes. Each node gets a\n",
    "prediction from a GNN that **never optimized for it**.\n",
    "\n",
    "**Leakage hardening in this section:**\n",
    "- **Fold-safe feature scaling:** metadata normalization is fit on each fold's train nodes only, then applied to all nodes for that fold.\n",
    "- **No outer-val model selection:** we do not early-stop or checkpoint-pick using outer validation labels; each fold trains for a fixed schedule and predicts once."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# BotRGCN: Build node features + Precompute graph components ===\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "# Load exported arrays with aligned user IDs and labels.\n",
    "xgb_data = np.load(\"rgcn_features/xgb_features.npz\", allow_pickle=True)\n",
    "xlmr_data = np.load(\"rgcn_features/xlmr_features.npz\", allow_pickle=True)\n",
    "\n",
    "xgb_aids = list(xgb_data[\"author_ids\"])\n",
    "xlmr_aids = list(xlmr_data[\"author_ids\"])\n",
    "xlmr_vecs = xlmr_data[\"xlmr_feature_vectors\"]\n",
    "is_bot_raw = xgb_data[\"is_bot\"]\n",
    "\n",
    "# Canonical node order shared across all inputs.\n",
    "author_ids = sorted(set(xgb_aids) & set(xlmr_aids))\n",
    "xgb_idx = {aid: i for i, aid in enumerate(xgb_aids)}\n",
    "xlmr_idx = {aid: i for i, aid in enumerate(xlmr_aids)}\n",
    "xlmr_feature_vectors = np.array(\n",
    "    [xlmr_vecs[xlmr_idx[a]] for a in author_ids],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "is_bot = np.array([int(is_bot_raw[xgb_idx[a]]) for a in author_ids])\n",
    "\n",
    "# Use raw metadata features from the XGBoost pipeline and apply fold-wise scaling later.\n",
    "xgb_raw = combined_df.drop_duplicates(\"author_id\").set_index(\"author_id\")\n",
    "xgb_feature_vectors = np.array(\n",
    "    [xgb_raw.loc[a, feature_cols].values for a in author_ids],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "xgb_feature_vectors = np.nan_to_num(xgb_feature_vectors, 0.0)\n",
    "\n",
    "num_users = xgb_feature_vectors.shape[0]\n",
    "feature_dim = xgb_feature_vectors.shape[1] + xlmr_feature_vectors.shape[1]\n",
    "author_id_to_idx = {aid: i for i, aid in enumerate(author_ids)}\n",
    "\n",
    "print(f\"Loaded {num_users} users, feature dim = {feature_dim}\")\n",
    "print(f\"  Metadata features: {xgb_feature_vectors.shape[1]}d (raw; fold-scaled in Cell 8)\")\n",
    "print(f\"  XLMR embeddings:   {xlmr_feature_vectors.shape[1]}d (OOF [CLS])\")\n",
    "\n",
    "# --- Precompute similarity matrices + explicit edges (fold-independent) ---\n",
    "# kNN edge construction is deferred to Cell 8 (per-fold rebuild).\n",
    "\n",
    "user_hashtags, user_hours, username_to_id = defaultdict(list), defaultdict(list), {}\n",
    "for did in DATASET_IDS:\n",
    "    data_raw = load_posts_and_users(did)\n",
    "    username_to_id.update({u.get(\"username\", \"\").lower(): u[\"id\"]\n",
    "                           for u in data_raw[\"users\"] if u.get(\"username\")})\n",
    "    for p in data_raw[\"posts\"]:\n",
    "        aid = p[\"author_id\"]\n",
    "        if aid not in author_id_to_idx: continue\n",
    "        text = p.get(\"text\", \"\") or \"\"\n",
    "        user_hashtags[aid].extend(t.lower() for t in re.findall(r\"#([A-Za-z0-9_]+)\", text))\n",
    "        try: user_hours[aid].append(dtparser.isoparse(p[\"created_at\"]).hour)\n",
    "        except Exception: pass\n",
    "\n",
    "def knn_edges_train_targets(sim_matrix, k, train_mask):\n",
    "    \"\"\"Directed kNN where every target is a train node (no val->val edges).\"\"\"\n",
    "    src, tgt = [], []\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        sims = sim_matrix[i].copy()\n",
    "        sims[i] = -1; sims[~train_mask] = -1\n",
    "        n_pos = (sims > 0).sum()\n",
    "        if n_pos == 0: continue\n",
    "        top_k = np.argpartition(sims, -min(k, n_pos))[-min(k, n_pos):]\n",
    "        for j in top_k:\n",
    "            if sims[j] > 0: src.append(i); tgt.append(j)\n",
    "    return src, tgt\n",
    "\n",
    "# Precompute similarity matrices (label-free, reused across folds)\n",
    "ht_docs = [\" \".join(user_hashtags[aid]) if user_hashtags[aid] else \"\" for aid in author_ids]\n",
    "ht_sim = cosine_similarity(TfidfVectorizer(token_pattern=r\"[a-z0-9_]+\").fit_transform(ht_docs))\n",
    "\n",
    "hour_hist = np.zeros((num_users, 24), dtype=np.float32)\n",
    "for idx, aid in enumerate(author_ids):\n",
    "    for h in user_hours[aid]: hour_hist[idx, h] += 1\n",
    "norms = np.linalg.norm(hour_hist, axis=1, keepdims=True); norms[norms == 0] = 1\n",
    "time_sim = (hour_hist / norms) @ (hour_hist / norms).T\n",
    "\n",
    "# Precompute explicit edges (label-free, fixed across folds)\n",
    "mention_src, mention_tgt, bio_src, bio_tgt = [], [], [], []\n",
    "for did in DATASET_IDS:\n",
    "    data_raw = load_posts_and_users(did)\n",
    "    for p in data_raw[\"posts\"]:\n",
    "        sid = p[\"author_id\"]\n",
    "        if sid not in author_id_to_idx: continue\n",
    "        for m in re.findall(r\"@([A-Za-z0-9_]+)\", p.get(\"text\", \"\")):\n",
    "            tid = username_to_id.get(m.lower())\n",
    "            if tid and tid in author_id_to_idx and tid != sid:\n",
    "                mention_src.append(author_id_to_idx[sid]); mention_tgt.append(author_id_to_idx[tid])\n",
    "    for u in data_raw[\"users\"]:\n",
    "        sid = u[\"id\"]\n",
    "        if sid not in author_id_to_idx: continue\n",
    "        for m in re.findall(r\"@([A-Za-z0-9_]+)\", u.get(\"description\", \"\") or \"\"):\n",
    "            tid = username_to_id.get(m.lower())\n",
    "            if tid and tid in author_id_to_idx and tid != sid:\n",
    "                bio_src.append(author_id_to_idx[sid]); bio_tgt.append(author_id_to_idx[tid])\n",
    "\n",
    "NUM_RELATIONS = 4\n",
    "print(f\"Loaded {num_users} users, feature dim = {feature_dim}\")\n",
    "print(f\"  Metadata features: {xgb_feature_vectors.shape[1]}d (raw; fold-scaled in Cell 8)\")\n",
    "print(f\"  XLMR embeddings:   {xlmr_feature_vectors.shape[1]}d (OOF [CLS])\")\n",
    "print(f\"Precomputed: ht_sim {ht_sim.shape}, time_sim {time_sim.shape}\")\n",
    "print(f\"Explicit edges: {len(mention_src)} mentions, {len(bio_src)} bio-links\")\n",
    "print(f\"kNN graph will be rebuilt per fold in Cell 8\")\n"
   ],
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Loaded 889 users, feature dim = 803\n",
      "  Metadata features: 35d (raw; fold-scaled in Cell 8)\n",
      "  XLMR embeddings:   768d (OOF [CLS])\n",
      "Loaded 889 users, feature dim = 803\n",
      "  Metadata features: 35d (raw; fold-scaled in Cell 8)\n",
      "  XLMR embeddings:   768d (OOF [CLS])\n",
      "Precomputed: ht_sim (889, 889), time_sim (889, 889)\n",
      "Explicit edges: 1 mentions, 2 bio-links\n",
      "kNN graph will be rebuilt per fold in Cell 8\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === BotRGCN K-Fold OOF Predictions ===\n\nclass BotRGCN(nn.Module):\n    def __init__(self, in_dim, hidden_dim=64, out_dim=2, num_relations=2, dropout=0.3):\n        super().__init__()\n        self.conv1 = RGCNConv(in_dim, hidden_dim, num_relations=num_relations)\n        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations=num_relations)\n        self.classifier = nn.Linear(hidden_dim, out_dim)\n        self.dropout = dropout\n    def forward(self, x, edge_index, edge_type):\n        x = F.dropout(F.relu(self.conv1(x, edge_index, edge_type)), p=self.dropout, training=self.training)\n        x = F.dropout(F.relu(self.conv2(x, edge_index, edge_type)), p=self.dropout, training=self.training)\n        return self.classifier(x)\n\ndef edge_dropout(ei, et, drop_rate=0.25):\n    if drop_rate <= 0:\n        return ei, et\n    keep = torch.rand(ei.size(1), device=ei.device) >= drop_rate\n    return ei[:, keep], et[keep]\n\n\ndef compute_class_weights(y, mask, dev):\n    yt = y[mask]\n    n = yt.size(0)\n    nc = yt.unique().size(0)\n    w = torch.ones(nc, device=dev)\n    for c in range(nc):\n        w[c] = n / (nc * (yt == c).sum().float().clamp(min=1))\n    return w\n\nrgcn_device = torch.device(\"mps\" if torch.backends.mps.is_available()\n                            else \"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"GNN device: {rgcn_device}\")\n\ny_gnn = torch.tensor(is_bot, dtype=torch.long)\n\n# --- K-Fold OOF loop ---\nskf_gnn = StratifiedKFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\ngnn_oof_probs = np.zeros(num_users, dtype=np.float64)\ngnn_oof_fold = np.full(num_users, -1, dtype=np.int32)\n\nfor fold, (tr_idx, val_idx) in enumerate(skf_gnn.split(np.arange(num_users), is_bot), 1):\n    fold_train_mask = torch.zeros(num_users, dtype=torch.bool)\n    fold_train_mask[tr_idx] = True\n    fold_val_mask = torch.zeros(num_users, dtype=torch.bool)\n    fold_val_mask[val_idx] = True\n\n    # Fit metadata scaler on this fold's train users only.\n    fold_scaler = StandardScaler()\n    fold_scaler.fit(xgb_feature_vectors[tr_idx])\n    xgb_scaled_fold = fold_scaler.transform(xgb_feature_vectors).astype(np.float32)\n\n    fold_node_features = np.concatenate(\n        [xgb_scaled_fold, xlmr_feature_vectors],\n        axis=1,\n    ).astype(np.float32)\n    fold_x = torch.from_numpy(fold_node_features)\n\n    # Rebuild kNN edges each fold so validation nodes only point to train targets.\n    fold_train_mask_np = np.zeros(num_users, dtype=bool)\n    fold_train_mask_np[tr_idx] = True\n\n    ht_src, ht_tgt = knn_edges_train_targets(ht_sim, KNN_K, fold_train_mask_np)\n    ts_src, ts_tgt = knn_edges_train_targets(time_sim, KNN_K, fold_train_mask_np)\n\n    # Fold-gate mention and bio edges: restrict targets to train nodes\n    # (consistent with kNN edge handling to prevent val->val leakage).\n    fold_mention_src = [s for s, t in zip(mention_src, mention_tgt) if fold_train_mask_np[t]]\n    fold_mention_tgt = [t for s, t in zip(mention_src, mention_tgt) if fold_train_mask_np[t]]\n    fold_bio_src = [s for s, t in zip(bio_src, bio_tgt) if fold_train_mask_np[t]]\n    fold_bio_tgt = [t for s, t in zip(bio_src, bio_tgt) if fold_train_mask_np[t]]\n\n    all_src = ht_src + ts_src + fold_mention_src + fold_bio_src\n    all_tgt = ht_tgt + ts_tgt + fold_mention_tgt + fold_bio_tgt\n    all_rel = (\n        [0] * len(ht_src)\n        + [1] * len(ts_src)\n        + [2] * len(fold_mention_src)\n        + [3] * len(fold_bio_src)\n    )\n\n    fold_edge_index = torch.tensor([all_src, all_tgt], dtype=torch.long)\n    fold_edge_type = torch.tensor(all_rel, dtype=torch.long)\n    print(f\"  Fold {fold} graph: {fold_edge_index.size(1)} edges\")\n\n    fold_data = Data(\n        x=fold_x.to(rgcn_device), edge_index=fold_edge_index.to(rgcn_device),\n        edge_type=fold_edge_type.to(rgcn_device), y=y_gnn.clone().to(rgcn_device),\n        train_mask=fold_train_mask.to(rgcn_device), val_mask=fold_val_mask.to(rgcn_device))\n\n    fold_gnn = BotRGCN(in_dim=feature_dim, hidden_dim=GNN_HIDDEN, out_dim=2,\n                        num_relations=NUM_RELATIONS, dropout=0.3).to(rgcn_device)\n    cw = compute_class_weights(fold_data.y, fold_data.train_mask, rgcn_device)\n    loss_fn = nn.CrossEntropyLoss(weight=cw)\n    optimizer = torch.optim.Adam(fold_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=GNN_EPOCHS)\n\n    for epoch in range(1, GNN_EPOCHS + 1):\n        fold_gnn.train()\n        optimizer.zero_grad()\n\n        ei, et = edge_dropout(fold_data.edge_index, fold_data.edge_type, 0.25)\n        logits_train = fold_gnn(fold_data.x, ei, et)[fold_data.train_mask]\n        labels_train = fold_data.y[fold_data.train_mask]\n        loss = loss_fn(logits_train, labels_train)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    # No outer-val checkpoint selection: evaluate exactly once after fixed training.\n    fold_gnn.eval()\n    with torch.no_grad():\n        logits = fold_gnn(fold_data.x, fold_data.edge_index, fold_data.edge_type)\n        probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n        preds = logits.argmax(dim=1).cpu().numpy()\n\n    gnn_oof_probs[val_idx] = probs[val_idx]\n    gnn_oof_fold[val_idx] = fold\n    val_acc = (preds[val_idx] == is_bot[val_idx]).mean()\n    val_f1 = f1_score(is_bot[val_idx], (probs[val_idx] >= 0.5).astype(int), average=\"binary\")\n    print(f\"Fold {fold}: Val Acc={val_acc:.4f}  Val F1={val_f1:.4f}  (val size={len(val_idx)})\")\n\n    del fold_gnn, fold_data\n    if rgcn_device.type == \"mps\": torch.mps.empty_cache()\n\nassert np.isfinite(gnn_oof_probs).all(), \"BotRGCN OOF contains non-finite values\"\nassert (gnn_oof_fold > 0).all(), \"Some users are missing BotRGCN OOF fold assignments\"\n\ngnn_oof_f1 = f1_score(is_bot, (gnn_oof_probs >= 0.5).astype(int), average=\"binary\")\nprint(f\"\\nBotRGCN OOF F1 (all {num_users} users): {gnn_oof_f1:.4f}\")\n"
   ],
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "GNN device: mps\n",
      "  Fold 1 graph: 17133 edges\n",
      "Fold 1: Val Acc=0.9663  Val F1=0.9143  (val size=178)\n",
      "  Fold 2 graph: 17129 edges\n",
      "Fold 2: Val Acc=0.9607  Val F1=0.9136  (val size=178)\n",
      "  Fold 3 graph: 16987 edges\n",
      "Fold 3: Val Acc=0.9551  Val F1=0.8889  (val size=178)\n",
      "  Fold 4 graph: 17099 edges\n",
      "Fold 4: Val Acc=0.9663  Val F1=0.9231  (val size=178)\n",
      "  Fold 5 graph: 17089 edges\n",
      "Fold 5: Val Acc=0.9548  Val F1=0.8947  (val size=177)\n",
      "\n",
      "BotRGCN OOF F1 (all 889 users): 0.9072\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === OOF Integrity Checks + Utility Functions ===\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    log_loss,\n",
    "    brier_score_loss,\n",
    ")\n",
    "\n",
    "\n",
    "def assert_oof_integrity(\n",
    "    author_ids_seq,\n",
    "    labels,\n",
    "    xgb_probs,\n",
    "    xlmr_probs,\n",
    "    gnn_probs,\n",
    "    xgb_folds,\n",
    "    xlmr_folds,\n",
    "    gnn_folds,\n",
    "):\n",
    "    n = len(author_ids_seq)\n",
    "    assert len(set(author_ids_seq)) == n, \"Duplicate author_id entries in canonical order\"\n",
    "    assert len(labels) == n, \"Label length mismatch\"\n",
    "\n",
    "    for name, arr in [(\"XGB\", xgb_probs), (\"XLMR\", xlmr_probs), (\"GNN\", gnn_probs)]:\n",
    "        assert len(arr) == n, f\"{name} probability length mismatch\"\n",
    "        assert np.isfinite(arr).all(), f\"{name} contains non-finite probabilities\"\n",
    "        assert ((arr >= 0.0) & (arr <= 1.0)).all(), f\"{name} contains out-of-range probabilities\"\n",
    "\n",
    "    for name, arr in [(\"XGB\", xgb_folds), (\"XLMR\", xlmr_folds), (\"GNN\", gnn_folds)]:\n",
    "        assert len(arr) == n, f\"{name} fold-id length mismatch\"\n",
    "        assert (arr > 0).all(), f\"{name} has missing fold assignments\"\n",
    "\n",
    "\n",
    "def best_f1_threshold(y_true, probs, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 181)\n",
    "    best_t, best_f1 = 0.5, -1.0\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_true, (probs >= t).astype(int), average=\"binary\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = float(t)\n",
    "    return best_t, float(best_f1)\n",
    "\n",
    "\n",
    "def oof_metrics_at_threshold(y_true, probs, threshold):\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"f1\": float(f1_score(y_true, preds, average=\"binary\")),\n",
    "        \"precision\": float(precision_score(y_true, preds, average=\"binary\", zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, preds, average=\"binary\", zero_division=0)),\n",
    "        \"accuracy\": float(accuracy_score(y_true, preds)),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def calibrate_probs_cv(y_true, probs, seed=RANDOM_STATE, methods=(\"sigmoid\", \"isotonic\")):\n",
    "    \"\"\"Leakage-safe calibration via nested CV over existing OOF scores.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    probs = np.asarray(probs)\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    best = {\n",
    "        \"method\": \"raw\",\n",
    "        \"probs\": probs.copy(),\n",
    "        \"log_loss\": float(log_loss(y_true, np.clip(probs, 1e-6, 1 - 1e-6))),\n",
    "        \"brier\": float(brier_score_loss(y_true, probs)),\n",
    "    }\n",
    "\n",
    "    for method in methods:\n",
    "        cal_probs = np.zeros_like(probs)\n",
    "        for tr_idx, va_idx in inner_cv.split(np.zeros(len(y_true)), y_true):\n",
    "            p_tr = np.clip(probs[tr_idx], 1e-6, 1 - 1e-6)\n",
    "            y_tr = y_true[tr_idx]\n",
    "            p_va = np.clip(probs[va_idx], 1e-6, 1 - 1e-6)\n",
    "\n",
    "            if method == \"sigmoid\":\n",
    "                # Platt scaling on a single score feature.\n",
    "                cal = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "                cal.fit(p_tr.reshape(-1, 1), y_tr)\n",
    "                cal_probs[va_idx] = cal.predict_proba(p_va.reshape(-1, 1))[:, 1]\n",
    "            elif method == \"isotonic\":\n",
    "                cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "                cal.fit(p_tr, y_tr)\n",
    "                cal_probs[va_idx] = cal.transform(p_va)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported calibration method: {method}\")\n",
    "\n",
    "        ll = float(log_loss(y_true, np.clip(cal_probs, 1e-6, 1 - 1e-6)))\n",
    "        br = float(brier_score_loss(y_true, cal_probs))\n",
    "        if ll < best[\"log_loss\"]:\n",
    "            best = {\"method\": method, \"probs\": cal_probs, \"log_loss\": ll, \"brier\": br}\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "# `assert_oof_integrity` is called after `meta_df` creation so every array\n",
    "# is checked in the same canonical user order.\n",
    "print(\"Utility functions defined.\")"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Utility functions defined.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build & Train the Meta-Learner\n",
    "\n",
    "All three models now have honest OOF predictions for **all 889 users**.\n",
    "The meta-learner trains on the full dataset with nested CV for unbiased evaluation.\n",
    "\n",
    "*Nested CV ensures we report meta-learner performance on held-out predictions; the reported F1 is a fair estimate of deployment performance.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Build Meta-Learner on ALL users: calibration + thresholds + artifacts ===\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_predict, GridSearchCV\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, precision_score, recall_score,\n    classification_report, confusion_matrix\n)\n\n\ndef build_meta_features(X_raw):\n    \"\"\"Augment 3 base-learner probs with pairwise interactions and disagreement.\"\"\"\n    return np.column_stack([\n        X_raw,\n        X_raw[:, 0] * X_raw[:, 1],   # XGB * XLMR\n        X_raw[:, 0] * X_raw[:, 2],   # XGB * GNN\n        X_raw[:, 1] * X_raw[:, 2],   # XLMR * GNN\n        np.max(X_raw, axis=1),        # max agreement\n        np.std(X_raw, axis=1),        # disagreement signal\n    ])\n\n# Map author_id \u2192 OOF probabilities and fold ids\nxgb_aid_to_prob = dict(zip(combined_df[\"author_id\"], xgb_oof_probs))\nxlmr_aid_to_prob = dict(zip(text_combined_df[\"author_id\"], xlmr_oof_probs))\ngnn_aid_to_prob = dict(zip(author_ids, gnn_oof_probs))\n\nxgb_aid_to_fold = dict(zip(combined_df[\"author_id\"], xgb_oof_fold))\nxlmr_aid_to_fold = dict(zip(text_combined_df[\"author_id\"], xlmr_oof_fold))\ngnn_aid_to_fold = dict(zip(author_ids, gnn_oof_fold))\n\nmeta_rows = []\nfor aid in author_ids:\n    xgb_p = xgb_aid_to_prob.get(aid)\n    xlmr_p = xlmr_aid_to_prob.get(aid)\n    gnn_p = gnn_aid_to_prob.get(aid)\n    if xgb_p is not None and xlmr_p is not None and gnn_p is not None:\n        meta_rows.append({\n            \"User_ID\": aid,\n            \"XGB_Prob\": float(xgb_p),\n            \"XLMR_Prob\": float(xlmr_p),\n            \"GNN_Prob\": float(gnn_p),\n            \"XGB_Fold\": int(xgb_aid_to_fold[aid]),\n            \"XLMR_Fold\": int(xlmr_aid_to_fold[aid]),\n            \"GNN_Fold\": int(gnn_aid_to_fold[aid]),\n            \"True_Label\": int(is_bot[author_id_to_idx[aid]]),\n        })\n\nmeta_df = pd.DataFrame(meta_rows)\nassert len(meta_df) == len(author_ids), \"Meta DataFrame missing users due alignment issues\"\nassert meta_df[\"User_ID\"].is_unique, \"Meta DataFrame has duplicate users\"\ny_meta = meta_df[\"True_Label\"].values\n\n# OOF integrity check on properly aligned columns (all keyed by meta_df row order)\nassert_oof_integrity(\n    meta_df[\"User_ID\"].tolist(),\n    meta_df[\"True_Label\"].values,\n    meta_df[\"XGB_Prob\"].values,\n    meta_df[\"XLMR_Prob\"].values,\n    meta_df[\"GNN_Prob\"].values,\n    meta_df[\"XGB_Fold\"].values,\n    meta_df[\"XLMR_Fold\"].values,\n    meta_df[\"GNN_Fold\"].values,\n)\nprint(\"OOF integrity checks passed (aligned via meta_df).\")\n\nprint(f\"Meta-learner DataFrame: {len(meta_df)} users  (all OOF)\")\nprint(f\"  Bots:   {(meta_df['True_Label'] == 1).sum()}\")\nprint(f\"  Humans: {(meta_df['True_Label'] == 0).sum()}\")\n\n# --- Calibration candidates (leakage-safe CV-on-OOF) ---\ncalibration_results = {\n    \"XGB\": calibrate_probs_cv(y_meta, meta_df[\"XGB_Prob\"].values, seed=RANDOM_STATE),\n    \"XLMR\": calibrate_probs_cv(y_meta, meta_df[\"XLMR_Prob\"].values, seed=RANDOM_STATE),\n    \"GNN\": calibrate_probs_cv(y_meta, meta_df[\"GNN_Prob\"].values, seed=RANDOM_STATE),\n}\n\nmeta_df[\"XGB_Prob_Cal\"] = calibration_results[\"XGB\"][\"probs\"]\nmeta_df[\"XLMR_Prob_Cal\"] = calibration_results[\"XLMR\"][\"probs\"]\nmeta_df[\"GNN_Prob_Cal\"] = calibration_results[\"GNN\"][\"probs\"]\n\nprint(\"\\n--- Calibration selection by log-loss (CV-on-OOF) ---\")\nfor key in [\"XGB\", \"XLMR\", \"GNN\"]:\n    res = calibration_results[key]\n    print(f\"  {key:>4s}: method={res['method']:<8s}  log_loss={res['log_loss']:.5f}  brier={res['brier']:.5f}\")\n\n\n# --- Evaluate raw vs calibrated stack with nested CV + C tuning ---\ndef eval_meta_stack(X_meta, y_true, seed):\n    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n    probs = np.zeros(len(y_true), dtype=np.float64)\n    best_Cs = []\n    for train_idx, val_idx in outer_cv.split(X_meta, y_true):\n        inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n        grid = GridSearchCV(\n            LogisticRegression(solver=\"lbfgs\", max_iter=1000),\n            param_grid={\"C\": [0.01, 0.1, 1.0, 10.0]},\n            cv=inner_cv, scoring=\"f1\", refit=True,\n        )\n        grid.fit(X_meta[train_idx], y_true[train_idx])\n        probs[val_idx] = grid.predict_proba(X_meta[val_idx])[:, 1]\n        best_Cs.append(grid.best_params_[\"C\"])\n    preds = (probs >= 0.5).astype(int)\n    # Use the most common C across outer folds as the representative best C.\n    from collections import Counter\n    best_C = Counter(best_Cs).most_common(1)[0][0]\n    return {\n        \"probs\": probs,\n        \"preds\": preds,\n        \"f1\": float(f1_score(y_true, preds, average=\"binary\")),\n        \"accuracy\": float(accuracy_score(y_true, preds)),\n        \"precision\": float(precision_score(y_true, preds, average=\"binary\", zero_division=0)),\n        \"recall\": float(recall_score(y_true, preds, average=\"binary\", zero_division=0)),\n        \"best_C\": float(best_C),\n    }\n\n\nX_meta_raw = build_meta_features(meta_df[[\"XGB_Prob\", \"XLMR_Prob\", \"GNN_Prob\"]].values)\nX_meta_cal = build_meta_features(meta_df[[\"XGB_Prob_Cal\", \"XLMR_Prob_Cal\", \"GNN_Prob_Cal\"]].values)\n\nraw_eval = eval_meta_stack(X_meta_raw, y_meta, RANDOM_STATE)\ncal_eval = eval_meta_stack(X_meta_cal, y_meta, RANDOM_STATE)\n\nbest_variant_by_cv = \"calibrated\" if cal_eval[\"f1\"] >= raw_eval[\"f1\"] else \"raw\"\n\n# Let nested CV decide which variant to use (calibrated if it wins or ties).\nselected_variant = best_variant_by_cv\nif selected_variant == \"calibrated\":\n    X_meta = X_meta_cal\n    meta_cv_probs = cal_eval[\"probs\"]\n    meta_cv_preds = cal_eval[\"preds\"]\n    stack_eval = cal_eval\nelse:\n    X_meta = X_meta_raw\n    meta_cv_probs = raw_eval[\"probs\"]\n    meta_cv_preds = raw_eval[\"preds\"]\n    stack_eval = raw_eval\n\nprint(\"\\n--- Stack variant selection (by nested-CV F1) ---\")\nprint(f\"  raw F1={raw_eval['f1']:.4f} (C={raw_eval['best_C']}) | calibrated F1={cal_eval['f1']:.4f} (C={cal_eval['best_C']})\")\nprint(f\"  Selected variant: {selected_variant}\")\n\n# --- Threshold optimization on OOF probabilities ---\nthresholds = {}\nmetrics_default = {}\nmetrics_opt = {}\n\nbase_prob_cols = [\n    (\"XGBoost\", \"XGB_Prob\" if selected_variant == \"raw\" else \"XGB_Prob_Cal\"),\n    (\"XLM-R\", \"XLMR_Prob\" if selected_variant == \"raw\" else \"XLMR_Prob_Cal\"),\n    (\"BotRGCN\", \"GNN_Prob\" if selected_variant == \"raw\" else \"GNN_Prob_Cal\"),\n]\n\nfor name, col in base_prob_cols:\n    probs = meta_df[col].values\n    t_opt, _ = best_f1_threshold(y_meta, probs)\n    thresholds[name] = t_opt\n    metrics_default[name] = oof_metrics_at_threshold(y_meta, probs, 0.5)\n    metrics_opt[name] = oof_metrics_at_threshold(y_meta, probs, t_opt)\n\nensemble_t_opt, _ = best_f1_threshold(y_meta, meta_cv_probs)\nthresholds[\"Ensemble\"] = ensemble_t_opt\nmetrics_default[\"Ensemble\"] = oof_metrics_at_threshold(y_meta, meta_cv_probs, 0.5)\nmetrics_opt[\"Ensemble\"] = oof_metrics_at_threshold(y_meta, meta_cv_probs, ensemble_t_opt)\n\nprint(\"\\n\" + \"=\" * 72)\nprint(\"  Meta-Learner Nested CV Performance\")\nprint(\"=\" * 72)\nprint(f\"  Accuracy:  {stack_eval['accuracy']:.4f}\")\nprint(f\"  F1 (bot):  {stack_eval['f1']:.4f}\")\nprint(f\"  Precision: {stack_eval['precision']:.4f}\")\nprint(f\"  Recall:    {stack_eval['recall']:.4f}\")\n\nprint(\"\\n--- Threshold comparison (0.5 vs optimized) ---\")\nfor key in [\"XGBoost\", \"XLM-R\", \"BotRGCN\", \"Ensemble\"]:\n    d = metrics_default[key]\n    o = metrics_opt[key]\n    print(\n        f\"  {key:>8s}: F1@0.5={d['f1']:.4f} | F1@opt={o['f1']:.4f} \"\n        f\"(t={thresholds[key]:.3f})\"\n    )\n\nbest_individual_f1 = max(metrics_opt[\"XGBoost\"][\"f1\"], metrics_opt[\"XLM-R\"][\"f1\"], metrics_opt[\"BotRGCN\"][\"f1\"])\nensemble_f1 = metrics_opt[\"Ensemble\"][\"f1\"]\nprint(f\"\\n  Ensemble F1@opt: {ensemble_f1:.4f}\")\nprint(f\"  Best Single@opt: {best_individual_f1:.4f}\")\nprint(f\"  Improvement: {ensemble_f1 - best_individual_f1:+.4f}\")\n\n# --- Persist core artifacts ---\nrun_dir = ensure_run_dir(seed=RANDOM_STATE, calibration_mode=selected_variant)\nmeta_df_out = meta_df.copy()\nmeta_df_out[\"Ensemble_Prob_OOF\"] = meta_cv_probs\nmeta_df_out.to_csv(run_dir / \"oof_predictions.csv\", index=False)\n\nwith open(run_dir / \"thresholds.json\", \"w\") as f:\n    json.dump({k: float(v) for k, v in thresholds.items()}, f, indent=2)\n\nrun_config = {\n    \"seed\": RANDOM_STATE,\n    \"cv_folds\": K,\n    \"selected_variant\": selected_variant,\n    \"best_variant_by_cv\": best_variant_by_cv,\n    \"calibration_methods\": {k: v[\"method\"] for k, v in calibration_results.items()},\n    \"metrics_default\": metrics_default,\n    \"metrics_opt\": metrics_opt,\n    \"device\": str(torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")),\n}\nwith open(run_dir / \"run_config.json\", \"w\") as f:\n    json.dump(run_config, f, indent=2)\n\nprint(f\"\\nSaved artifacts to: {run_dir}\")"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "OOF integrity checks passed (aligned via meta_df).\n",
      "Meta-learner DataFrame: 889 users  (all OOF)\n",
      "  Bots:   184\n",
      "  Humans: 705\n",
      "\n",
      "--- Calibration selection by log-loss (CV-on-OOF) ---\n",
      "   XGB: method=raw       log_loss=0.14650  brier=0.04099\n",
      "  XLMR: method=isotonic  log_loss=0.12468  brier=0.02847\n",
      "   GNN: method=sigmoid   log_loss=0.11789  brier=0.02942\n",
      "\n",
      "--- Stack variant selection (by nested-CV F1) ---\n",
      "  raw F1=0.9600 (C=10.0) | calibrated F1=0.9676 (C=10.0)\n",
      "  Selected variant: calibrated\n",
      "\n",
      "========================================================================\n",
      "  Meta-Learner Nested CV Performance\n",
      "========================================================================\n",
      "  Accuracy:  0.9865\n",
      "  F1 (bot):  0.9676\n",
      "  Precision: 0.9624\n",
      "  Recall:    0.9728\n",
      "\n",
      "--- Threshold comparison (0.5 vs optimized) ---\n",
      "   XGBoost: F1@0.5=0.8636 | F1@opt=0.8767 (t=0.340)\n",
      "     XLM-R: F1@0.5=0.8950 | F1@opt=0.9117 (t=0.520)\n",
      "   BotRGCN: F1@0.5=0.9185 | F1@opt=0.9185 (t=0.435)\n",
      "  Ensemble: F1@0.5=0.9676 | F1@opt=0.9755 (t=0.595)\n",
      "\n",
      "  Ensemble F1@opt: 0.9755\n",
      "  Best Single@opt: 0.9185\n",
      "  Improvement: +0.0570\n",
      "\n",
      "Saved artifacts to: artifacts/ensemble/run_20260214_113408_seed42_calibrated\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Final model + diagnostics ===\n",
    "import pickle\n",
    "\n",
    "# Use the best C from the winning variant's grid search\n",
    "best_C = stack_eval[\"best_C\"]\n",
    "meta_model = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=1000)\n",
    "meta_model.fit(X_meta, y_meta)\n",
    "\n",
    "# Feature weights (8 features: 3 raw + 3 pairwise + max + std)\n",
    "feature_names = [\"XGBoost\", \"XLM-R\", \"BotRGCN\",\n",
    "                 \"XGB*XLMR\", \"XGB*GNN\", \"XLMR*GNN\", \"Max\", \"Disagreement\"]\n",
    "w = meta_model.coef_[0]\n",
    "rel = np.abs(w) / np.abs(w).sum() * 100\n",
    "print(f\"Meta-Learner Weights (C={best_C}, variant={selected_variant}):\")\n",
    "for name, wi, pct in zip(feature_names, w, rel):\n",
    "    print(f\"  {name:>12s}: {wi:+.3f}  ({pct:.0f}%)\")\n",
    "print(f\"  {'Intercept':>12s}: {meta_model.intercept_[0]:+.3f}\")\n",
    "\n",
    "# Classification report (nested CV \u2014 unbiased)\n",
    "print(f\"\\n{classification_report(y_meta, meta_cv_preds, target_names=['Human', 'Bot'])}\")\n",
    "cm = confusion_matrix(y_meta, meta_cv_preds)\n",
    "print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "# Save model in both legacy path and artifact run path.\n",
    "with open(\"meta_learner.pkl\", \"wb\") as f:\n",
    "    pickle.dump(meta_model, f)\n",
    "with open(run_dir / \"meta_learner.pkl\", \"wb\") as f:\n",
    "    pickle.dump(meta_model, f)\n",
    "\n",
    "with open(run_dir / \"calibration_summary.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            key: {\n",
    "                \"method\": val[\"method\"],\n",
    "                \"log_loss\": float(val[\"log_loss\"]),\n",
    "                \"brier\": float(val[\"brier\"]),\n",
    "            }\n",
    "            for key, val in calibration_results.items()\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# Persist calibrators if calibrated variant was selected\n",
    "if selected_variant == \"calibrated\":\n",
    "    calibrator_artifacts = {}\n",
    "    for key in [\"XGB\", \"XLMR\", \"GNN\"]:\n",
    "        method = calibration_results[key][\"method\"]\n",
    "        probs_full = meta_df[f\"{key}_Prob\"].values\n",
    "        if method == \"sigmoid\":\n",
    "            cal = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "            cal.fit(np.clip(probs_full, 1e-6, 1 - 1e-6).reshape(-1, 1), y_meta)\n",
    "        elif method == \"isotonic\":\n",
    "            cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "            cal.fit(np.clip(probs_full, 1e-6, 1 - 1e-6), y_meta)\n",
    "        else:\n",
    "            cal = None\n",
    "        calibrator_artifacts[key] = {\"method\": method, \"calibrator\": cal}\n",
    "    with open(run_dir / \"calibrators.pkl\", \"wb\") as f:\n",
    "        pickle.dump(calibrator_artifacts, f)\n",
    "    cal_desc = \", \".join(f\"{k}={v['method']}\" for k, v in calibrator_artifacts.items())\n",
    "    print(f\"Persisted calibrators ({cal_desc})\")\n",
    "\n",
    "print(\n",
    "    f\"\\nSaved meta_learner.pkl and calibration summary to {run_dir} | \"\n",
    "    f\"Ensemble F1@opt={ensemble_f1:.4f} (best single={best_individual_f1:.4f}, \"\n",
    "    f\"+{ensemble_f1 - best_individual_f1:.4f})\"\n",
    ")"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Meta-Learner Weights (C=10.0, variant=calibrated):\n",
      "       XGBoost: +5.432  (26%)\n",
      "         XLM-R: +0.961  (5%)\n",
      "       BotRGCN: +2.631  (12%)\n",
      "      XGB*XLMR: +1.428  (7%)\n",
      "       XGB*GNN: +3.349  (16%)\n",
      "      XLMR*GNN: +2.972  (14%)\n",
      "           Max: +3.708  (17%)\n",
      "  Disagreement: +0.732  (3%)\n",
      "     Intercept: -9.242\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Human       0.99      0.99      0.99       705\n",
      "         Bot       0.96      0.97      0.97       184\n",
      "\n",
      "    accuracy                           0.99       889\n",
      "   macro avg       0.98      0.98      0.98       889\n",
      "weighted avg       0.99      0.99      0.99       889\n",
      "\n",
      "Confusion matrix:\n",
      "[[698   7]\n",
      " [  5 179]]\n",
      "Persisted calibrators (XGB=raw, XLMR=isotonic, GNN=sigmoid)\n",
      "\n",
      "Saved meta_learner.pkl and calibration summary to artifacts/ensemble/run_20260214_113408_seed42_calibrated | Ensemble F1@opt=0.9755 (best single=0.9185, +0.0570)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Base Learner Error Correlation Analysis\n",
    "# Checks whether the three base learners make independent errors (good for stacking)\n",
    "# or correlated errors (limited stacking gain).\n",
    "\n",
    "xgb_pred = (meta_df[\"XGB_Prob\"].values >= thresholds.get(\"XGBoost\", 0.5)).astype(int)\n",
    "xlmr_pred = (meta_df[\"XLMR_Prob\"].values >= thresholds.get(\"XLM-R\", 0.5)).astype(int)\n",
    "gnn_pred = (meta_df[\"GNN_Prob\"].values >= thresholds.get(\"BotRGCN\", 0.5)).astype(int)\n",
    "\n",
    "xgb_err = (xgb_pred != y_meta).astype(int)\n",
    "xlmr_err = (xlmr_pred != y_meta).astype(int)\n",
    "gnn_err = (gnn_pred != y_meta).astype(int)\n",
    "\n",
    "err_corr = np.corrcoef(np.vstack([xgb_err, xlmr_err, gnn_err]))\n",
    "print(\"Error correlation matrix (lower = more complementary):\")\n",
    "print(pd.DataFrame(err_corr, index=[\"XGB\", \"XLMR\", \"GNN\"], columns=[\"XGB\", \"XLMR\", \"GNN\"]).round(3))\n",
    "\n",
    "# Agreement breakdown\n",
    "all_agree = ((xgb_pred == xlmr_pred) & (xlmr_pred == gnn_pred)).sum()\n",
    "any_disagree = len(y_meta) - all_agree\n",
    "print(f\"\\nAll 3 agree: {all_agree}/{len(y_meta)} ({all_agree/len(y_meta)*100:.1f}%)\")\n",
    "print(f\"Disagreements: {any_disagree} ({any_disagree/len(y_meta)*100:.1f}%)\")\n",
    "\n",
    "# Per-model error counts\n",
    "for name, errs in [(\"XGB\", xgb_err), (\"XLMR\", xlmr_err), (\"GNN\", gnn_err)]:\n",
    "    print(f\"  {name} errors: {errs.sum()}\")\n",
    "\n",
    "# Where exactly one model is wrong (ensemble can correct these)\n",
    "one_wrong = (xgb_err + xlmr_err + gnn_err == 1).sum()\n",
    "two_wrong = (xgb_err + xlmr_err + gnn_err == 2).sum()\n",
    "all_wrong = (xgb_err + xlmr_err + gnn_err == 3).sum()\n",
    "print(f\"\\nRecoverable (1 wrong): {one_wrong}  |  Marginal (2 wrong): {two_wrong}  |  Irrecoverable (3 wrong): {all_wrong}\")"
   ],
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Error correlation matrix (lower = more complementary):\n",
      "        XGB   XLMR    GNN\n",
      "XGB   1.000  0.032 -0.024\n",
      "XLMR  0.032  1.000  0.634\n",
      "GNN  -0.024  0.634  1.000\n",
      "\n",
      "All 3 agree: 798/889 (89.8%)\n",
      "Disagreements: 91 (10.2%)\n",
      "  XGB errors: 45\n",
      "  XLMR errors: 35\n",
      "  GNN errors: 39\n",
      "\n",
      "Recoverable (1 wrong): 66  |  Marginal (2 wrong): 25  |  Irrecoverable (3 wrong): 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Multi-seed stability report (meta-level CV + calibration/threshold selection) ===\n",
    "SEED_LIST = [42, 1337, 2026]\n",
    "seed_rows = []\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    xgb_cal = calibrate_probs_cv(y_meta, meta_df[\"XGB_Prob\"].values, seed=seed)\n",
    "    xlmr_cal = calibrate_probs_cv(y_meta, meta_df[\"XLMR_Prob\"].values, seed=seed)\n",
    "    gnn_cal = calibrate_probs_cv(y_meta, meta_df[\"GNN_Prob\"].values, seed=seed)\n",
    "\n",
    "    X_raw = build_meta_features(meta_df[[\"XGB_Prob\", \"XLMR_Prob\", \"GNN_Prob\"]].values)\n",
    "    X_cal = build_meta_features(np.column_stack([xgb_cal[\"probs\"], xlmr_cal[\"probs\"], gnn_cal[\"probs\"]]))\n",
    "\n",
    "    raw_eval_seed = eval_meta_stack(X_raw, y_meta, seed)\n",
    "    cal_eval_seed = eval_meta_stack(X_cal, y_meta, seed)\n",
    "\n",
    "    if cal_eval_seed[\"f1\"] >= raw_eval_seed[\"f1\"]:\n",
    "        chosen = \"calibrated\"\n",
    "        probs_seed = cal_eval_seed[\"probs\"]\n",
    "        eval_seed = cal_eval_seed\n",
    "    else:\n",
    "        chosen = \"raw\"\n",
    "        probs_seed = raw_eval_seed[\"probs\"]\n",
    "        eval_seed = raw_eval_seed\n",
    "\n",
    "    t_opt_seed, f1_opt_seed = best_f1_threshold(y_meta, probs_seed)\n",
    "    seed_rows.append(\n",
    "        {\n",
    "            \"seed\": int(seed),\n",
    "            \"selected_variant\": chosen,\n",
    "            \"f1_at_0_5\": float(eval_seed[\"f1\"]),\n",
    "            \"threshold_opt\": float(t_opt_seed),\n",
    "            \"f1_at_opt\": float(f1_opt_seed),\n",
    "            \"accuracy\": float(eval_seed[\"accuracy\"]),\n",
    "            \"precision\": float(eval_seed[\"precision\"]),\n",
    "            \"recall\": float(eval_seed[\"recall\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "seed_df = pd.DataFrame(seed_rows).sort_values(\"seed\").reset_index(drop=True)\n",
    "print(\"Multi-seed ensemble stability (meta-level):\")\n",
    "print(seed_df)\n",
    "print(\n",
    "    f\"\\nF1@opt mean={seed_df['f1_at_opt'].mean():.4f} \"\n",
    "    f\"std={seed_df['f1_at_opt'].std(ddof=1):.4f}\"\n",
    ")\n",
    "\n",
    "seed_summary = {\n",
    "    \"seeds\": [int(s) for s in SEED_LIST],\n",
    "    \"rows\": seed_rows,\n",
    "    \"f1_opt_mean\": float(seed_df[\"f1_at_opt\"].mean()),\n",
    "    \"f1_opt_std\": float(seed_df[\"f1_at_opt\"].std(ddof=1)),\n",
    "    \"recommended_seed\": int(seed_df.sort_values([\"f1_at_opt\", \"f1_at_0_5\"], ascending=False).iloc[0][\"seed\"]),\n",
    "    \"notes\": \"XLM-R base checkpoints are fixed exports; this seed sweep captures meta-level CV and calibration variability.\",\n",
    "}\n",
    "\n",
    "seed_df.to_csv(run_dir / \"seed_summary.csv\", index=False)\n",
    "with open(run_dir / \"seed_summary.json\", \"w\") as f:\n",
    "    json.dump(seed_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nSaved seed summary artifacts to: {run_dir}\")"
   ],
   "execution_count": 72,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Multi-seed ensemble stability (meta-level):\n",
      "   seed selected_variant  f1_at_0_5  threshold_opt  f1_at_opt  accuracy  \\\n",
      "0    42       calibrated   0.967568          0.595   0.975477  0.986502   \n",
      "1  1337       calibrated   0.965147          0.510   0.970350  0.985377   \n",
      "2  2026       calibrated   0.967914          0.540   0.973118  0.986502   \n",
      "\n",
      "   precision    recall  \n",
      "0   0.962366  0.972826  \n",
      "1   0.952381  0.978261  \n",
      "2   0.952632  0.983696  \n",
      "\n",
      "F1@opt mean=0.9730 std=0.0026\n",
      "\n",
      "Saved seed summary artifacts to: artifacts/ensemble/run_20260214_113408_seed42_calibrated\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full-Data Training Mode (No Splits)\n",
    "\n",
    "This section trains all available components on the entire labeled set for final competition inference.\n",
    "\n",
    "Notes:\n",
    "- This is a deployment-oriented path (not an unbiased evaluation path).\n",
    "- It intentionally avoids CV/train-val splits during fitting.\n",
    "- Uses the `selected_variant` (raw or calibrated) chosen by nested CV in Section 4.\n",
    "- If calibrated, calibrators are persisted alongside full-data artifacts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Full-data training/export (no splits) ===\n",
    "# Trains XGB, GNN, and meta-learner on all labeled users.\n",
    "# XLM-R probabilities are produced by averaging available fold checkpoints over all users.\n",
    "\n",
    "import pickle\n",
    "\n",
    "if \"xgb\" not in globals():\n",
    "    import xgboost as xgb\n",
    "\n",
    "set_global_seed(RANDOM_STATE)\n",
    "run_dir_full = ensure_run_dir(seed=RANDOM_STATE, calibration_mode=f\"full_data_{selected_variant}\")\n",
    "print(f\"Full-data run dir: {run_dir_full}\")\n",
    "\n",
    "# 1) XGBoost on full labeled set\n",
    "full_scale = (y_all == 0).sum() / max(y_all.sum(), 1)\n",
    "xgb_full_model = xgb.XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=full_scale,\n",
    "    colsample_bytree=0.5,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "xgb_full_model.fit(X_all, y_all)\n",
    "xgb_full_probs = xgb_full_model.predict_proba(X_all)[:, 1]\n",
    "xgb_full_map = dict(zip(combined_df[\"author_id\"], xgb_full_probs))\n",
    "\n",
    "# 2) XLM-R probabilities for all users (mean over available fold checkpoints)\n",
    "text_full_df = text_combined_df.drop_duplicates(\"author_id\", keep=\"first\").reset_index(drop=True)\n",
    "text_full_ds = Dataset.from_pandas(text_full_df[[\"text\"]].reset_index(drop=True))\n",
    "text_full_ds = text_full_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "text_full_ds.set_format(\"torch\")\n",
    "\n",
    "available_ckpts = []\n",
    "for fold in range(1, K + 1):\n",
    "    try:\n",
    "        ckpt = resolve_best_xlmr_checkpoint(fold)\n",
    "        if ckpt not in available_ckpts:\n",
    "            available_ckpts.append(ckpt)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "assert available_ckpts, \"No XLM-R checkpoints found for full-data inference\"\n",
    "print(f\"Using {len(available_ckpts)} XLM-R checkpoints for probability averaging\")\n",
    "\n",
    "xlmr_prob_stack = []\n",
    "for ckpt in available_ckpts:\n",
    "    print(f\"  XLM-R infer: {ckpt}\")\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(ckpt, num_labels=2).to(device)\n",
    "    mdl.eval()\n",
    "    logits_all = []\n",
    "    with torch.no_grad():\n",
    "        for batch in DataLoader(text_full_ds, batch_size=8, shuffle=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits_all.append(mdl(**batch).logits.cpu().numpy())\n",
    "    logits_all = np.concatenate(logits_all, axis=0)\n",
    "    xlmr_prob_stack.append(softmax(logits_all, axis=1)[:, 1])\n",
    "    del mdl\n",
    "    gc.collect()\n",
    "    if device.type == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "xlmr_full_probs = np.mean(np.vstack(xlmr_prob_stack), axis=0)\n",
    "xlmr_full_map = dict(zip(text_full_df[\"author_id\"], xlmr_full_probs))\n",
    "\n",
    "# 3) BotRGCN on full graph with all nodes in train mask\n",
    "all_train_np = np.ones(num_users, dtype=bool)\n",
    "ht_src, ht_tgt = knn_edges_train_targets(ht_sim, KNN_K, all_train_np)\n",
    "ts_src, ts_tgt = knn_edges_train_targets(time_sim, KNN_K, all_train_np)\n",
    "full_src = ht_src + ts_src + mention_src + bio_src\n",
    "full_tgt = ht_tgt + ts_tgt + mention_tgt + bio_tgt\n",
    "full_rel = [0] * len(ht_src) + [1] * len(ts_src) + [2] * len(mention_src) + [3] * len(bio_src)\n",
    "full_edge_index = torch.tensor([full_src, full_tgt], dtype=torch.long)\n",
    "full_edge_type = torch.tensor(full_rel, dtype=torch.long)\n",
    "\n",
    "xgb_scaled_full = StandardScaler().fit_transform(xgb_feature_vectors).astype(np.float32)\n",
    "node_features_full = np.concatenate([xgb_scaled_full, xlmr_feature_vectors], axis=1).astype(np.float32)\n",
    "x_full = torch.from_numpy(node_features_full)\n",
    "\n",
    "data_full = Data(\n",
    "    x=x_full.to(rgcn_device),\n",
    "    edge_index=full_edge_index.to(rgcn_device),\n",
    "    edge_type=full_edge_type.to(rgcn_device),\n",
    "    y=torch.tensor(is_bot, dtype=torch.long).to(rgcn_device),\n",
    "    train_mask=torch.ones(num_users, dtype=torch.bool).to(rgcn_device),\n",
    ")\n",
    "\n",
    "gnn_full_model = BotRGCN(in_dim=feature_dim, hidden_dim=GNN_HIDDEN, out_dim=2, num_relations=NUM_RELATIONS, dropout=0.3).to(rgcn_device)\n",
    "full_cw = compute_class_weights(data_full.y, data_full.train_mask, rgcn_device)\n",
    "full_loss_fn = nn.CrossEntropyLoss(weight=full_cw)\n",
    "full_opt = torch.optim.Adam(gnn_full_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "full_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(full_opt, T_max=GNN_EPOCHS)\n",
    "\n",
    "for epoch in range(1, GNN_EPOCHS + 1):\n",
    "    gnn_full_model.train()\n",
    "    full_opt.zero_grad()\n",
    "    ei, et = edge_dropout(data_full.edge_index, data_full.edge_type, 0.25)\n",
    "    loss = full_loss_fn(gnn_full_model(data_full.x, ei, et)[data_full.train_mask], data_full.y[data_full.train_mask])\n",
    "    loss.backward()\n",
    "    full_opt.step()\n",
    "    full_scheduler.step()\n",
    "\n",
    "gnn_full_model.eval()\n",
    "with torch.no_grad():\n",
    "    gnn_full_logits = gnn_full_model(data_full.x, data_full.edge_index, data_full.edge_type)\n",
    "    gnn_full_probs = F.softmax(gnn_full_logits, dim=1)[:, 1].cpu().numpy()\n",
    "gnn_full_map = dict(zip(author_ids, gnn_full_probs))\n",
    "\n",
    "# 4) Train meta-learner on full stacked features\n",
    "full_rows = []\n",
    "for aid in author_ids:\n",
    "    if aid in xgb_full_map and aid in xlmr_full_map and aid in gnn_full_map:\n",
    "        full_rows.append(\n",
    "            {\n",
    "                \"User_ID\": aid,\n",
    "                \"XGB_Prob\": float(xgb_full_map[aid]),\n",
    "                \"XLMR_Prob\": float(xlmr_full_map[aid]),\n",
    "                \"GNN_Prob\": float(gnn_full_map[aid]),\n",
    "                \"True_Label\": int(is_bot[author_id_to_idx[aid]]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "meta_full_df = pd.DataFrame(full_rows)\n",
    "assert len(meta_full_df) == len(author_ids), \"Full-data meta frame is misaligned\"\n",
    "\n",
    "X_meta_full = build_meta_features(meta_full_df[[\"XGB_Prob\", \"XLMR_Prob\", \"GNN_Prob\"]].values)\n",
    "y_meta_full = meta_full_df[\"True_Label\"].values\n",
    "\n",
    "meta_full_model = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=1000)\n",
    "meta_full_model.fit(X_meta_full, y_meta_full)\n",
    "\n",
    "meta_full_probs = meta_full_model.predict_proba(X_meta_full)[:, 1]\n",
    "ensemble_t_opt_full, _ = best_f1_threshold(y_meta_full, meta_full_probs)\n",
    "\n",
    "thresholds_full = {\n",
    "    \"XGBoost\": best_f1_threshold(y_meta_full, meta_full_df[\"XGB_Prob\"].values)[0],\n",
    "    \"XLM-R\": best_f1_threshold(y_meta_full, meta_full_df[\"XLMR_Prob\"].values)[0],\n",
    "    \"BotRGCN\": best_f1_threshold(y_meta_full, meta_full_df[\"GNN_Prob\"].values)[0],\n",
    "    \"Ensemble\": float(ensemble_t_opt_full),\n",
    "}\n",
    "\n",
    "# 5) Save full-data artifacts\n",
    "meta_full_df_out = meta_full_df.copy()\n",
    "meta_full_df_out[\"Ensemble_Prob\"] = meta_full_probs\n",
    "meta_full_df_out.to_csv(run_dir_full / \"full_data_predictions.csv\", index=False)\n",
    "\n",
    "with open(run_dir_full / \"thresholds_full_data.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in thresholds_full.items()}, f, indent=2)\n",
    "\n",
    "with open(run_dir_full / \"meta_learner_full_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(meta_full_model, f)\n",
    "\n",
    "with open(run_dir_full / \"xgb_full_data_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_full_model, f)\n",
    "\n",
    "# Save GNN weights\n",
    "torch.save(gnn_full_model.state_dict(), run_dir_full / \"botrgcn_full_data.pth\")\n",
    "\n",
    "# Copy calibrators to full-data run dir if using calibrated variant\n",
    "if selected_variant == \"calibrated\" and \"calibrator_artifacts\" in globals():\n",
    "    with open(run_dir_full / \"calibrators.pkl\", \"wb\") as f:\n",
    "        pickle.dump(calibrator_artifacts, f)\n",
    "\n",
    "full_report = {\n",
    "    \"mode\": \"full_data_no_splits\",\n",
    "    \"n_users\": int(len(meta_full_df)),\n",
    "    \"ensemble_f1_train_opt\": float(f1_score(y_meta_full, (meta_full_probs >= ensemble_t_opt_full).astype(int), average=\"binary\")),\n",
    "    \"ensemble_f1_train_at_0_5\": float(f1_score(y_meta_full, (meta_full_probs >= 0.5).astype(int), average=\"binary\")),\n",
    "    \"ensemble_threshold\": float(ensemble_t_opt_full),\n",
    "    \"notes\": \"Training-set metrics are optimistic; use for deployment artifact generation only.\",\n",
    "}\n",
    "\n",
    "with open(run_dir_full / \"full_data_run_report.json\", \"w\") as f:\n",
    "    json.dump(full_report, f, indent=2)\n",
    "\n",
    "print(\"\\nFull-data training complete.\")\n",
    "print(f\"Users: {len(meta_full_df)}\")\n",
    "print(f\"Ensemble train F1@0.5: {full_report['ensemble_f1_train_at_0_5']:.4f}\")\n",
    "print(f\"Ensemble train F1@opt: {full_report['ensemble_f1_train_opt']:.4f} at t={ensemble_t_opt_full:.3f}\")\n",
    "print(f\"Artifacts: {run_dir_full}\")"
   ],
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Full-data run dir: artifacts/ensemble/run_20260214_113409_seed42_full_data_calibrated\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 889/889 [00:00<00:00, 1897.46 examples/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Using 5 XLM-R checkpoints for probability averaging\n",
      "  XLM-R infer: xlmr_cv/fold1_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1614.32it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  XLM-R infer: xlmr_cv/fold2_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1411.20it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  XLM-R infer: xlmr_cv/fold3_phase3/checkpoint-135\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1514.44it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  XLM-R infer: xlmr_cv/fold4_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1559.11it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "  XLM-R infer: xlmr_cv/fold5_phase3/checkpoint-90\n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1495.67it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Full-data training complete.\n",
      "Users: 889\n",
      "Ensemble train F1@0.5: 1.0000\n",
      "Ensemble train F1@opt: 1.0000 at t=0.050\n",
      "Artifacts: artifacts/ensemble/run_20260214_113409_seed42_full_data_calibrated\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "NEW_JSON_PATH = Path(\"dataset.posts&users.34.json\")\n",
    "OUTPUT_CSV = Path(\"new_data_predictions.csv\")\n",
    "\n",
    "\n",
    "def _latest_full_data_run_dir(base_dir=ARTIFACTS_BASE_DIR):\n",
    "    if not base_dir.exists():\n",
    "        return None\n",
    "    cands = [p for p in base_dir.glob(\"run_*_full_data_*\") if p.is_dir()]\n",
    "    if not cands:\n",
    "        # fallback: any run dir that has full-data artifacts\n",
    "        cands = [p for p in base_dir.glob(\"run_*\") if (p / \"thresholds_full_data.json\").exists()]\n",
    "    if not cands:\n",
    "        return None\n",
    "    return sorted(cands)[-1]\n",
    "\n",
    "\n",
    "def _build_user_text_df_from_json(data_json):\n",
    "    by_author = defaultdict(list)\n",
    "    for p in data_json[\"posts\"]:\n",
    "        by_author[p[\"author_id\"]].append(preprocess_text(p.get(\"text\", \"\") or \"\"))\n",
    "    rows = []\n",
    "    for aid, texts in by_author.items():\n",
    "        text = \" [SEP] \".join(t for t in texts if t)\n",
    "        rows.append({\"author_id\": aid, \"text\": text if text else \"\"})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "assert NEW_JSON_PATH.exists(), f\"Missing file: {NEW_JSON_PATH}\"\n",
    "\n",
    "# Load full-data artifacts if models are not already in memory.\n",
    "latest_full_dir = _latest_full_data_run_dir()\n",
    "if \"meta_full_model\" not in globals():\n",
    "    assert latest_full_dir is not None, \"No full-data run directory found under artifacts/ensemble\"\n",
    "    import pickle as _pickle\n",
    "    with open(latest_full_dir / \"meta_learner_full_data.pkl\", \"rb\") as f:\n",
    "        meta_full_model = _pickle.load(f)\n",
    "\n",
    "if \"xgb_full_model\" not in globals():\n",
    "    assert latest_full_dir is not None, \"No full-data run directory found under artifacts/ensemble\"\n",
    "    import pickle as _pickle\n",
    "    with open(latest_full_dir / \"xgb_full_data_model.pkl\", \"rb\") as f:\n",
    "        xgb_full_model = _pickle.load(f)\n",
    "\n",
    "if \"thresholds_full\" not in globals():\n",
    "    if latest_full_dir is None:\n",
    "        latest_full_dir = _latest_full_data_run_dir()\n",
    "    assert latest_full_dir is not None, \"No full-data run directory found under artifacts/ensemble\"\n",
    "    with open(latest_full_dir / \"thresholds_full_data.json\") as f:\n",
    "        thresholds_full = json.load(f)\n",
    "\n",
    "if \"gnn_full_model\" not in globals():\n",
    "    if latest_full_dir is None:\n",
    "        latest_full_dir = _latest_full_data_run_dir()\n",
    "    assert latest_full_dir is not None, \"No full-data run directory found under artifacts/ensemble\"\n",
    "    gnn_full_model = BotRGCN(in_dim=feature_dim, hidden_dim=GNN_HIDDEN, out_dim=2, num_relations=NUM_RELATIONS, dropout=0.3).to(rgcn_device)\n",
    "    gnn_full_model.load_state_dict(torch.load(latest_full_dir / \"botrgcn_full_data.pth\", map_location=rgcn_device))\n",
    "    gnn_full_model.eval()\n",
    "\n",
    "# Parse new JSON + metadata features\n",
    "with open(NEW_JSON_PATH) as f:\n",
    "    new_data = json.load(f)\n",
    "\n",
    "new_posts = new_data[\"posts\"]\n",
    "new_users = new_data[\"users\"]\n",
    "new_lang = new_data.get(\"lang\", \"en\")\n",
    "\n",
    "new_df = extract_user_features(new_posts, new_users, bot_ids=set())\n",
    "new_df[\"levenshtein_name_dist\"] = new_df[\"author_id\"].map(\n",
    "    {u[\"id\"]: levenshtein_distance((u.get(\"username\", \"\") or \"\").lower(), (u.get(\"name\", \"\") or \"\").lower()) for u in new_users}\n",
    ")\n",
    "new_df[\"digit_density\"] = new_df[\"author_id\"].map(\n",
    "    {u[\"id\"]: digit_density(u.get(\"username\", \"\")) for u in new_users}\n",
    ")\n",
    "\n",
    "new_by_author_ts = defaultdict(list)\n",
    "for p in new_posts:\n",
    "    new_by_author_ts[p[\"author_id\"]].append(pd.to_datetime(p[\"created_at\"]))\n",
    "new_df[\"iat_entropy\"] = new_df[\"author_id\"].map({aid: iat_entropy(ts) for aid, ts in new_by_author_ts.items()})\n",
    "new_df[\"burstiness\"] = new_df[\"author_id\"].map({aid: burstiness(ts) for aid, ts in new_by_author_ts.items()})\n",
    "\n",
    "new_act = pd.DataFrame.from_dict(\n",
    "    {aid: activity_vector(ts) for aid, ts in new_by_author_ts.items()},\n",
    "    orient=\"index\",\n",
    "    columns=[f\"hour_{h}\" for h in range(24)],\n",
    ")\n",
    "new_act.index.name = \"author_id\"\n",
    "new_act = new_act.reset_index()\n",
    "new_df = new_df.merge(new_act, on=\"author_id\", how=\"left\")\n",
    "\n",
    "new_by_author_posts = defaultdict(list)\n",
    "for p in new_posts:\n",
    "    new_by_author_posts[p[\"author_id\"]].append(p)\n",
    "new_df[\"lang_mismatch_ratio\"] = new_df[\"author_id\"].map(\n",
    "    {aid: lang_mismatch_ratio(ap, new_lang) for aid, ap in new_by_author_posts.items()}\n",
    ")\n",
    "new_df[\"screen_name_entropy\"] = new_df[\"author_id\"].map(\n",
    "    {u[\"id\"]: screen_name_entropy(u.get(\"username\", \"\")) for u in new_users}\n",
    ")\n",
    "\n",
    "for c in feature_cols:\n",
    "    if c not in new_df.columns:\n",
    "        new_df[c] = 0.0\n",
    "new_df = new_df[[\"author_id\"] + feature_cols].copy()\n",
    "new_df[feature_cols] = new_df[feature_cols].fillna(0)\n",
    "\n",
    "xgb_new_probs = xgb_full_model.predict_proba(new_df[feature_cols])[:, 1]\n",
    "new_author_ids = new_df[\"author_id\"].tolist()\n",
    "\n",
    "# XLM-R probabilities + embeddings for new users\n",
    "new_text_df = _build_user_text_df_from_json(new_data)\n",
    "new_text_df = new_text_df.drop_duplicates(\"author_id\", keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "# Ensure all metadata users have a text row\n",
    "missing_text_ids = set(new_author_ids) - set(new_text_df[\"author_id\"])\n",
    "if missing_text_ids:\n",
    "    new_text_df = pd.concat(\n",
    "        [\n",
    "            new_text_df,\n",
    "            pd.DataFrame({\"author_id\": list(missing_text_ids), \"text\": [\"\" for _ in missing_text_ids]}),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "new_text_df = new_text_df.set_index(\"author_id\").loc[new_author_ids].reset_index()\n",
    "\n",
    "new_text_ds = Dataset.from_pandas(new_text_df[[\"text\"]].reset_index(drop=True))\n",
    "new_text_ds = new_text_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "new_text_ds.set_format(\"torch\")\n",
    "\n",
    "ckpts = []\n",
    "for fold in range(1, K + 1):\n",
    "    try:\n",
    "        ckpt = resolve_best_xlmr_checkpoint(fold)\n",
    "        if ckpt not in ckpts:\n",
    "            ckpts.append(ckpt)\n",
    "    except Exception:\n",
    "        pass\n",
    "assert ckpts, \"No XLM-R checkpoints available\"\n",
    "\n",
    "xlmr_prob_list = []\n",
    "for ckpt in ckpts:\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(ckpt, num_labels=2).to(device)\n",
    "    mdl.eval()\n",
    "    logits_chunks = []\n",
    "    with torch.no_grad():\n",
    "        for batch in DataLoader(new_text_ds, batch_size=8, shuffle=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits_chunks.append(mdl(**batch).logits.cpu().numpy())\n",
    "    logits_all = np.concatenate(logits_chunks, axis=0)\n",
    "    xlmr_prob_list.append(softmax(logits_all, axis=1)[:, 1])\n",
    "    del mdl\n",
    "    gc.collect()\n",
    "    if device.type == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "xlmr_new_probs = np.mean(np.vstack(xlmr_prob_list), axis=0)\n",
    "\n",
    "# Embeddings for GNN features: use first checkpoint's encoder CLS.\n",
    "emb_model = AutoModelForSequenceClassification.from_pretrained(ckpts[0], num_labels=2).to(device)\n",
    "emb_model.eval()\n",
    "new_xlmr_embs = []\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(new_text_ds, batch_size=8, shuffle=False):\n",
    "        out = emb_model.roberta(\n",
    "            input_ids=batch[\"input_ids\"].to(device),\n",
    "            attention_mask=batch[\"attention_mask\"].to(device),\n",
    "        )\n",
    "        new_xlmr_embs.append(out.last_hidden_state[:, 0, :].cpu().numpy())\n",
    "new_xlmr_emb = np.vstack(new_xlmr_embs).astype(np.float32)\n",
    "del emb_model\n",
    "if device.type == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "# GNN probabilities for new users via augmented graph inference\n",
    "old_ids = list(author_ids)\n",
    "combined_ids = old_ids + new_author_ids\n",
    "combined_idx = {aid: i for i, aid in enumerate(combined_ids)}\n",
    "\n",
    "# Scale metadata using train-distribution scaler (fit on existing known users only).\n",
    "xgb_scaler_full = StandardScaler().fit(xgb_feature_vectors)\n",
    "old_xgb_scaled = xgb_scaler_full.transform(xgb_feature_vectors).astype(np.float32)\n",
    "new_xgb_raw = new_df[feature_cols].values.astype(np.float32)\n",
    "new_xgb_scaled = xgb_scaler_full.transform(new_xgb_raw).astype(np.float32)\n",
    "\n",
    "combined_xgb = np.vstack([old_xgb_scaled, new_xgb_scaled]).astype(np.float32)\n",
    "combined_xlmr = np.vstack([xlmr_feature_vectors, new_xlmr_emb]).astype(np.float32)\n",
    "combined_x = torch.from_numpy(np.concatenate([combined_xgb, combined_xlmr], axis=1).astype(np.float32))\n",
    "\n",
    "# Rebuild hashtag/hour similarity for combined graph.\n",
    "combined_hashtags = {aid: list(user_hashtags.get(aid, [])) for aid in old_ids}\n",
    "combined_hours = {aid: list(user_hours.get(aid, [])) for aid in old_ids}\n",
    "for aid in new_author_ids:\n",
    "    combined_hashtags.setdefault(aid, [])\n",
    "    combined_hours.setdefault(aid, [])\n",
    "\n",
    "for p in new_posts:\n",
    "    aid = p[\"author_id\"]\n",
    "    if aid not in combined_idx:\n",
    "        continue\n",
    "    text = p.get(\"text\", \"\") or \"\"\n",
    "    tags = re.findall(r\"#([A-Za-z0-9_]+)\", text)\n",
    "    combined_hashtags[aid].extend(t.lower() for t in tags)\n",
    "    try:\n",
    "        combined_hours[aid].append(pd.to_datetime(p[\"created_at\"]).hour)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "ht_docs_combined = [\" \".join(combined_hashtags[aid]) if combined_hashtags[aid] else \"\" for aid in combined_ids]\n",
    "ht_sim_combined = cosine_similarity(TfidfVectorizer(token_pattern=r\"[a-z0-9_]+\").fit_transform(ht_docs_combined))\n",
    "\n",
    "hour_hist_combined = np.zeros((len(combined_ids), 24), dtype=np.float32)\n",
    "for i, aid in enumerate(combined_ids):\n",
    "    for h in combined_hours[aid]:\n",
    "        hour_hist_combined[i, h] += 1\n",
    "norms = np.linalg.norm(hour_hist_combined, axis=1, keepdims=True)\n",
    "norms[norms == 0] = 1\n",
    "time_sim_combined = (hour_hist_combined / norms) @ (hour_hist_combined / norms).T\n",
    "\n",
    "all_true_mask = np.ones(len(combined_ids), dtype=bool)\n",
    "ht_src_c, ht_tgt_c = knn_edges_train_targets(ht_sim_combined, KNN_K, all_true_mask)\n",
    "ts_src_c, ts_tgt_c = knn_edges_train_targets(time_sim_combined, KNN_K, all_true_mask)\n",
    "\n",
    "# Explicit edges: keep existing + add new posts/user bios edges.\n",
    "combined_username_to_id = dict(username_to_id)\n",
    "for u in new_users:\n",
    "    uname = (u.get(\"username\", \"\") or \"\").lower()\n",
    "    if uname:\n",
    "        combined_username_to_id[uname] = u[\"id\"]\n",
    "\n",
    "mention_src_c = list(mention_src)\n",
    "mention_tgt_c = list(mention_tgt)\n",
    "bio_src_c = list(bio_src)\n",
    "bio_tgt_c = list(bio_tgt)\n",
    "\n",
    "for p in new_posts:\n",
    "    sid = p[\"author_id\"]\n",
    "    if sid not in combined_idx:\n",
    "        continue\n",
    "    for m in re.findall(r\"@([A-Za-z0-9_]+)\", p.get(\"text\", \"\") or \"\"):\n",
    "        tid = combined_username_to_id.get(m.lower())\n",
    "        if tid and tid in combined_idx and tid != sid:\n",
    "            mention_src_c.append(combined_idx[sid])\n",
    "            mention_tgt_c.append(combined_idx[tid])\n",
    "\n",
    "for u in new_users:\n",
    "    sid = u[\"id\"]\n",
    "    if sid not in combined_idx:\n",
    "        continue\n",
    "    for m in re.findall(r\"@([A-Za-z0-9_]+)\", u.get(\"description\", \"\") or \"\"):\n",
    "        tid = combined_username_to_id.get(m.lower())\n",
    "        if tid and tid in combined_idx and tid != sid:\n",
    "            bio_src_c.append(combined_idx[sid])\n",
    "            bio_tgt_c.append(combined_idx[tid])\n",
    "\n",
    "edge_src_combined = ht_src_c + ts_src_c + mention_src_c + bio_src_c\n",
    "edge_tgt_combined = ht_tgt_c + ts_tgt_c + mention_tgt_c + bio_tgt_c\n",
    "edge_rel_combined = [0] * len(ht_src_c) + [1] * len(ts_src_c) + [2] * len(mention_src_c) + [3] * len(bio_src_c)\n",
    "\n",
    "edge_index_combined = torch.tensor([edge_src_combined, edge_tgt_combined], dtype=torch.long)\n",
    "edge_type_combined = torch.tensor(edge_rel_combined, dtype=torch.long)\n",
    "\n",
    "infer_data = Data(\n",
    "    x=combined_x.to(rgcn_device),\n",
    "    edge_index=edge_index_combined.to(rgcn_device),\n",
    "    edge_type=edge_type_combined.to(rgcn_device),\n",
    ")\n",
    "\n",
    "gnn_full_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_combined = gnn_full_model(infer_data.x, infer_data.edge_index, infer_data.edge_type)\n",
    "    probs_combined = F.softmax(logits_combined, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "gnn_new_probs = probs_combined[len(old_ids):]\n",
    "\n",
    "# Ensemble prediction (apply calibrators if selected_variant == \"calibrated\")\n",
    "\n",
    "xgb_new_p = xgb_new_probs.copy()\n",
    "xlmr_new_p = xlmr_new_probs.copy()\n",
    "gnn_new_p = gnn_new_probs.copy()\n",
    "\n",
    "# Load and apply calibrators if using calibrated variant\n",
    "if selected_variant == \"calibrated\":\n",
    "    if \"calibrator_artifacts\" not in globals():\n",
    "        cal_path = (latest_full_dir or _latest_full_data_run_dir())\n",
    "        if cal_path is not None and (cal_path / \"calibrators.pkl\").exists():\n",
    "            import pickle as _pickle\n",
    "            with open(cal_path / \"calibrators.pkl\", \"rb\") as f:\n",
    "                calibrator_artifacts = _pickle.load(f)\n",
    "        elif (run_dir / \"calibrators.pkl\").exists():\n",
    "            import pickle as _pickle\n",
    "            with open(run_dir / \"calibrators.pkl\", \"rb\") as f:\n",
    "                calibrator_artifacts = _pickle.load(f)\n",
    "    if \"calibrator_artifacts\" in globals():\n",
    "        def _apply_calibrator(probs_arr, key):\n",
    "            cal_obj = calibrator_artifacts[key][\"calibrator\"]\n",
    "            method = calibrator_artifacts[key][\"method\"]\n",
    "            if cal_obj is None:\n",
    "                return probs_arr\n",
    "            raw = np.clip(probs_arr, 1e-6, 1 - 1e-6)\n",
    "            if method == \"sigmoid\":\n",
    "                return cal_obj.predict_proba(raw.reshape(-1, 1))[:, 1]\n",
    "            elif method == \"isotonic\":\n",
    "                return cal_obj.transform(raw)\n",
    "            return probs_arr\n",
    "        xgb_new_p = _apply_calibrator(xgb_new_p, \"XGB\")\n",
    "        xlmr_new_p = _apply_calibrator(xlmr_new_p, \"XLMR\")\n",
    "        gnn_new_p = _apply_calibrator(gnn_new_p, \"GNN\")\n",
    "        cal_desc = \", \".join(f\"{k}={v['method']}\" for k, v in calibrator_artifacts.items())\n",
    "        print(f\"Applied calibrators: {cal_desc}\")\n",
    "\n",
    "X_new_meta = build_meta_features(np.column_stack([xgb_new_p, xlmr_new_p, gnn_new_p]))\n",
    "p_bot = meta_full_model.predict_proba(X_new_meta)[:, 1]\n",
    "ens_threshold = float(thresholds_full.get(\"Ensemble\", 0.5))\n",
    "pred_label = (p_bot >= ens_threshold).astype(int)\n",
    "\n",
    "pred_df = pd.DataFrame(\n",
    "    {\n",
    "        \"author_id\": new_author_ids,\n",
    "        \"XGB_Prob\": xgb_new_probs,\n",
    "        \"XLMR_Prob\": xlmr_new_probs,\n",
    "        \"GNN_Prob\": gnn_new_probs,\n",
    "        \"Ensemble_Prob\": p_bot,\n",
    "        \"Prediction\": pred_label,\n",
    "    }\n",
    ")\n",
    "\n",
    "pred_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved predictions to {OUTPUT_CSV}\")\n",
    "print(pred_df.head())"
   ],
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Map: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 438/438 [00:00<00:00, 1478.57 examples/s]\n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1646.62it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1365.30it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1596.17it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 972.04it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1417.52it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 1636.74it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n"
     ]
    },
    {
     "output_type": "stream",
     "text": [
      "Applied calibrators: XGB=raw, XLMR=isotonic, GNN=sigmoid\n",
      "Saved predictions to new_data_predictions.csv\n",
      "                              author_id  XGB_Prob  XLMR_Prob      GNN_Prob  \\\n",
      "0  d09db3e1-ba07-9615-9aed-e04de2ad81a7  0.048572   0.010915  6.818239e-05   \n",
      "1  e9520b4f-aac6-a766-9d6d-fb17b53b77f2  0.002735   0.042170  1.776218e-06   \n",
      "2  1ac40bd9-d485-a48c-94d9-97bfaa058d2c  0.009827   0.000373  6.207617e-11   \n",
      "3  3c7167d6-0c94-a62e-92a2-10c95e2ee098  0.026218   0.000659  9.519794e-09   \n",
      "4  8775797d-b1ea-a5bf-83dc-0fcdbea36ef3  0.001667   0.001319  3.762298e-10   \n",
      "\n",
      "   Ensemble_Prob  Prediction  \n",
      "0       0.000490           0  \n",
      "1       0.000531           0  \n",
      "2       0.000334           0  \n",
      "3       0.000356           0  \n",
      "4       0.000326           0  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === Export predicted bot IDs (competition submission format) ===\n",
    "# Reads the predictions CSV and writes one bot ID per line, matching dataset.bots.*.txt format.\n",
    "\n",
    "PREDICTIONS_CSV = Path(\"new_data_predictions.csv\")\n",
    "OUTPUT_BOTS_TXT = Path(\"predicted_bots.txt\")\n",
    "\n",
    "pred_df = pd.read_csv(PREDICTIONS_CSV)\n",
    "bot_ids = pred_df.loc[pred_df[\"Prediction\"] == 1, \"author_id\"].tolist()\n",
    "\n",
    "with open(OUTPUT_BOTS_TXT, \"w\") as f:\n",
    "    for bid in bot_ids:\n",
    "        f.write(f\"{bid}\\n\")\n",
    "\n",
    "print(f\"Wrote {len(bot_ids)} predicted bot IDs to {OUTPUT_BOTS_TXT}\")\n",
    "print(f\"Total users: {len(pred_df)}  |  Bots: {len(bot_ids)}  |  Humans: {len(pred_df) - len(bot_ids)}\")\n",
    "print(f\"\\nFirst 10 bot IDs:\")\n",
    "for bid in bot_ids[:10]:\n",
    "    print(f\"  {bid}\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}